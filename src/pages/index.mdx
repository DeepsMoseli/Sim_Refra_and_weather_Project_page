---
layout: ../layouts/Layout.astro
title: Simulating Refractive Distortions & Weather-Induced Artifacts for Resource-Constrained Autonomous Perception
authors:
  - name: Moseli Mots’oehli
    institution: University of Hawaiʻi at Mānoa; MindForge AI / The Shard (South Africa)
    notes: ["*", "†"]
  - name: Feimei Chen
    institution: University of Hawaiʻi at Mānoa
    notes: ["*"]
  - name: Hok Wai Chan
    institution: University of Hawaiʻi at Mānoa
    notes: ["*"]
  - name: Itumeleng Tlali
    institution: MindForge AI (South Africa)
    notes: ["*"]
  - name: Thulani Babeli, FRM
    institution: MindForge AI (South Africa)
    notes: ["*"]

conference: ICCV 2025 — CV4DC Workshop (Honolulu, HI), October 19, 2025
notes:
  - symbol: "*"
    text: author note one
  - symbol: †
    text: author note two
links:
  - name: Paper
    url: https://arxiv.org/pdf/2507.05536
    icon: ri:file-pdf-2-line
  - name: Code
    url: https://github.com/DeepsMoseli/RefraWeather-Sim
    icon: ri:github-line
  - name: arXiv
    url: https://arxiv.org/pdf/2507.05536
    icon: academicons:arxiv

# The color theme of the page. Defaults to "device" (the preference set in the user's brower or operating system). Setting this to "light" or "dark" will override the user's preference. This is useful if your figures only look good in one theme.
theme: device

# This is the icon that appears in the user's browser tab. To customize, change the favicon.svg file in /public/, or add your own file to /public/ and change the filename here.
favicon: favicon.svg

# These keys are optional. If a link to your project page is in a Google search result, text message, or social media post, it will often appear as a "link preview card" based on its title, description, favicon, and thumbnail. After you publish your page, you can double check that these previews look right using [this tool](https://linkpreview.xyz/)
description: Simple project page template for your research paper, built with Astro and Tailwind CSS
thumbnail: screenshot-light.png
---

import Video from "../components/Video.astro";
import HighlightedSection from "../components/HighlightedSection.astro";
import SmallCaps from "../components/SmallCaps.astro";
import Figure from "../components/Figure.astro";
import Picture from "../components/Picture.astro";
import TwoColumns from "../components/TwoColumns.astro";
import YouTubeVideo from "../components/YouTubeVideo.astro";
import LaTeX from "../components/LaTeX.astro";
import { ThreeDimensional } from "../components/ThreeDimensional.tsx";
import { Comparison } from "../components/Comparison.tsx";

import outside from "../assets/outside.mp4";
import transformer from "../assets/transformer.webp";

import framework from "../assets/framework.png";
import flare_orig from "../assets/flare_orig.png";
import flare_sim from "../assets/flare_sim.png";
import uniform_fog_orig from "../assets/uniform_fog_orig.png";
import uniform_fog_sim from "../assets/uniform_fog_sim.png";

import Table from "../components/Table.astro";
export const components = { table: Table }

<Video source={outside} />

<HighlightedSection>

## Abstract

The scarcity of autonomous vehicle datasets from developing regions, particularly across Africa’s diverse urban, rural, and unpaved roads, remains a key obstacle to robust
perception in low-resource settings. We present a procedural augmentation pipeline that enhances low-cost monocular dashcam footage with realistic refractive distortions and
weather-induced artifacts tailored to challenging African driving scenarios. Our refractive module simulates optical
effects from low-quality lenses and air turbulence, including lens distortion, Perlin noise, Thin-Plate Spline (TPS),and divergence-free (incompressible) warps. 
The weather module adds homogeneous fog, heterogeneous fog, and lens flare. To establish a benchmark, we provide baseline performance using three image restoration models. To support perception research in underrepresented African contexts,
without costly data collection, labeling, or simulation, we release our distortion toolkit, augmented dataset splits, and
benchmark results.

</HighlightedSection>

## Pipeline

Use the figure component to display images, videos, equations, or any other element, with an optional caption.

<Figure>
  <Picture slot="figure" src={framework} alt="Diagram of the transformer deep learning architecture." invertInDarkMode />
  <Fragment slot="caption">Overview of our two-stage restoration pipeline: a Synthetic Distortion Module applies random refractive distortions and weather artifacts; a Refractive U-Net predicts a dense UV displacement field to correct warps; and a Deweathering U-Net removes weather artifacts. The two models are trained separately.</Fragment>
</Figure>

If you stored your figures as PDFs, the `Picture` component can convert them into web-friendly images automatically.

<Figure>
  <Picture slot="figure" src="../assets/allstate-sparsity.pdf" alt="Impact of the sparsity-aware algorithm in XGBoost on the Allstate-10K dataset." invertInDarkMode />
  <Fragment slot="caption">Impact of the sparsity-aware algorithm in [XGBoost](https://arxiv.org/abs/1603.02754) on the Allstate-10K dataset.</Fragment>
</Figure>

Use the `Comparison` component to compare two elements with an interactive slider. It should work for any component or HTML element, including images, videos, and 3D models.

<Figure>
  <Comparison slot="figure" client:idle>
    <Picture slot="itemOne" src={uniform_fog_orig} alt="Original driving scene without fog effects" />
    <Picture slot="itemTwo" src={uniform_fog_sim} alt="Simulated driving scene with uniform fog applied" />
  </Comparison>
  <Fragment slot="caption">
    Comparison of a clear driving scene and its fog-augmented version generated using our uniform fog simulation. The method reduces visibility uniformly across depth.
  </Fragment>
</Figure>


<Figure>
  <Comparison slot="figure" client:idle>
    <Picture slot="itemOne" src={flare_orig} alt="Original driving scene without lens flare" />
    <Picture slot="itemTwo" src={flare_sim} alt="Simulated driving scene with lens flare artifacts" />
  </Comparison>
  <Fragment slot="caption">
    Comparison between a clear driving scene and its lens flare simulation. The flare overlay introduces realistic streaks and glare patterns to mimic sunlight reflections on the camera lens.
  </Fragment>
</Figure>



## Two columns

Use the two columns component to display two columns of content. In this example, the first column contains a figure with a YouTube video and the second column contains a figure with a custom [React](https://react.dev/) component. By default, they display side by side, but if the screen is narrow enough (for example, on mobile), they're arranged vertically.

<TwoColumns>
  <Figure slot="left">
    <YouTubeVideo slot="figure" videoId="wjZofJX0v4M" />
    <Fragment slot="caption">Take a look at this YouTube video.</Fragment>
  </Figure>
  <Figure slot="right">
    <ThreeDimensional slot="figure" filename="BoxVertexColors.glb" client:idle />
    <Fragment slot="caption">Now look at this cube, rendered with React Three Fiber.</Fragment>
  </Figure>
</TwoColumns>

## LaTeX

You can also add LaTeX formulas, rendered during the build process using [KaTeX](https://katex.org/) so they're quick to load for visitors of your project page. You can write them inline, like this: <LaTeX inline formula="a^2 + b^2 = c^2" />. Or, you can write them as a block:

<LaTeX formula="\int_a^b f(x) dx" />

## Results

Validation metrics for the refractive **R** and weather-induced artifact **W** image restoration. Here, L is the combined weighted loss, L_rec the L1 reconstruction loss, L_k the L1 k-map/UV loss, PSNR, and EPE as described in Section 4.2.*

| Model          | L     | L_rec | L_k    | PSNR  | EPE  |
| :------------- | :---: | :---: | :----: | :---: | :--: |
| *W* ResUnet    | 0.065 | 0.059 | 0.0070 | 32.54 |  –   |
| *W* SegFormer  | 0.096 | 0.086 | 0.0100 | 28.99 |  –   |
| *W* DDPM       | 0.054 | 0.051 | 0.0065 | 30.80 |  –   |
| *R* ResUnet    | 0.034 | 0.029 | 0.0050 | 23.24 | 5.76 |
| *R* SegFormer  | 0.146 | 0.085 | 0.0550 | 16.29 | 69.82|
| *R* DDPM       | 0.044 | 0.039 | 0.0048 | 22.80 | 6.01 |


## BibTeX citation

Displaying your BibTeX citation in a code block makes it easy to copy and paste.

```bibtex
@article{motsoehli2025refraweather,
  title   = {Simulating Refractive Distortions and Weather-Induced Artifacts for Resource-Constrained Autonomous Perception},
  author  = {Mots'oehli, Moseli and Chen, Feimei and Chan, Hok Wai and Tlali, Itumeleng and Babeli, Thulani and Baek, Kyungim and Chen, Huaijin},
  journal = {arXiv preprint arXiv:2507.05536},
  year    = {2025}
}
```